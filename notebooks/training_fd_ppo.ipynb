{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssCOanHc8JH_"
      },
      "source": [
        "# Training in Brax\n",
        "\n",
        "Once an environment is created in brax, we can quickly train it using brax's built-in training algorithms. Let's try it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "executionInfo": {
          "elapsed": 22308,
          "status": "ok",
          "timestamp": 1679686324614,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "kUrAlZTod7t_"
      },
      "outputs": [],
      "source": [
        "#@markdown ## âš ï¸ PLEASE NOTE:\n",
        "#@markdown This colab runs best using a GPU runtime.  From the Colab menu, choose Runtime > Change Runtime Type, then select **'GPU'** in the dropdown.\n",
        "\n",
        "import functools\n",
        "import jax\n",
        "import os\n",
        "\n",
        "from datetime import datetime\n",
        "from jax import numpy as jp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import HTML, clear_output\n",
        "\n",
        "\n",
        "import brax\n",
        "\n",
        "import flax\n",
        "from brax import envs\n",
        "from brax.io import model\n",
        "from brax.io import json\n",
        "from brax.io import html\n",
        "from brax.training.agents.ppo import train as ppo\n",
        "from brax.training.agents.sac import train as sac"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoyyw6pQ3xVJ"
      },
      "source": [
        "First let's pick an environment and a backend to train an agent in. \n",
        "\n",
        "Recall from the [Brax Basics](https://github.com/google/brax/blob/main/notebooks/basics.ipynb) colab, that the backend specifies which physics engine to use, each with different trade-offs between physical realism and training throughput/speed. The engines generally decrease in physical realism but increase in speed in the following order: `generalized`,  `positional`, then `spring`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "height": 480
        },
        "executionInfo": {
          "elapsed": 6143,
          "status": "ok",
          "timestamp": 1679686333304,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "4hHuDp53e4VJ",
        "outputId": "90d4c41b-9a25-4ca4-c6be-93172ea9ef57"
      },
      "outputs": [],
      "source": [
        "import importlib\n",
        "importlib.reload(brax)\n",
        "\n",
        "from brax.envs.fd.finger import Finger\n",
        "\n",
        "env = Finger()\n",
        "state = jax.jit(env.reset)(rng=jax.random.PRNGKey(seed=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMailSDb30t-"
      },
      "source": [
        "# Training\n",
        "\n",
        "Brax provides out of the box the following training algorithms:\n",
        "\n",
        "* [Proximal policy optimization](https://github.com/google/brax/blob/main/brax/training/agents/ppo/train.py)\n",
        "* [Soft actor-critic](https://github.com/google/brax/blob/main/brax/training/agents/sac/train.py)\n",
        "* [Evolutionary strategy](https://github.com/google/brax/blob/main/brax/training/agents/es/train.py)\n",
        "* [Analytic policy gradients](https://github.com/google/brax/blob/main/brax/training/agents/apg/train.py)\n",
        "* [Augmented random search](https://github.com/google/brax/blob/main/brax/training/agents/ars/train.py)\n",
        "\n",
        "Trainers take as input an environment function and some hyperparameters, and return an inference function to operate the environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3MA1UYlftuq"
      },
      "source": [
        "# Training\n",
        "\n",
        "Let's train the Ant policy using the `generalized` backend with PPO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "def create_wandb_run(alg_name, env_name, seed, notes, run_id=None):\n",
        "\n",
        "    name = f\"{alg_name}_{env_name}_sweep_{seed}\"\n",
        "\n",
        "    return wandb.init(\n",
        "        project=\"Brax\",\n",
        "        group=\"analytic_gradients\",\n",
        "        entity=\"alexanderwebb03-university-of-edinburgh\",\n",
        "        sync_tensorboard=True,\n",
        "        monitor_gym=True,\n",
        "        save_code=True,\n",
        "        name=name,\n",
        "        notes=notes,\n",
        "        id=run_id,\n",
        "        resume=run_id is not None,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "height": 321
        },
        "executionInfo": {
          "elapsed": 190263,
          "status": "ok",
          "timestamp": 1671658344336,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "FB6G2_Yt4A2m",
        "outputId": "402a0a43-3525-4eca-a425-ffcc71e8db0f"
      },
      "outputs": [],
      "source": [
        "# We determined some reasonable hyperparameters offline and share them here.\n",
        "env_name = 'finger'\n",
        "\n",
        "train_fn = {\n",
        "  'inverted_pendulum': functools.partial(ppo.train, num_timesteps=2_000_000, num_evals=20, reward_scaling=10, episode_length=1000, normalize_observations=True, action_repeat=1, unroll_length=5, num_minibatches=32, num_updates_per_batch=4, discounting=0.97, learning_rate=3e-4, entropy_cost=1e-2, num_envs=2048, batch_size=1024, seed=1),\n",
        "  'inverted_double_pendulum': functools.partial(ppo.train, num_timesteps=20_000_000, num_evals=20, reward_scaling=10, episode_length=1000, normalize_observations=True, action_repeat=1, unroll_length=5, num_minibatches=32, num_updates_per_batch=4, discounting=0.97, learning_rate=3e-4, entropy_cost=1e-2, num_envs=2048, batch_size=1024, seed=1),\n",
        "  'ant': functools.partial(ppo.train,  num_timesteps=50_000_000, num_evals=10, reward_scaling=10, episode_length=1000, normalize_observations=True, action_repeat=1, unroll_length=5, num_minibatches=32, num_updates_per_batch=4, discounting=0.97, learning_rate=3e-4, entropy_cost=1e-2, num_envs=4096, batch_size=2048, seed=1),\n",
        "  'humanoid': functools.partial(ppo.train,  num_timesteps=50_000_000, num_evals=10, reward_scaling=0.1, episode_length=1000, normalize_observations=True, action_repeat=1, unroll_length=10, num_minibatches=32, num_updates_per_batch=8, discounting=0.97, learning_rate=3e-4, entropy_cost=1e-3, num_envs=2048, batch_size=1024, seed=1),\n",
        "  'reacher': functools.partial(ppo.train, num_timesteps=50_000_000, num_evals=20, reward_scaling=5, episode_length=1000, normalize_observations=True, action_repeat=4, unroll_length=50, num_minibatches=32, num_updates_per_batch=8, discounting=0.95, learning_rate=3e-4, entropy_cost=1e-3, num_envs=2048, batch_size=256, max_devices_per_host=8, seed=1),\n",
        "  'humanoidstandup': functools.partial(ppo.train, num_timesteps=100_000_000, num_evals=20, reward_scaling=0.1, episode_length=1000, normalize_observations=True, action_repeat=1, unroll_length=15, num_minibatches=32, num_updates_per_batch=8, discounting=0.97, learning_rate=6e-4, entropy_cost=1e-2, num_envs=2048, batch_size=1024, seed=1),\n",
        "  'hopper': functools.partial(sac.train, num_timesteps=6_553_600, num_evals=20, reward_scaling=30, episode_length=1000, normalize_observations=True, action_repeat=1, discounting=0.997, learning_rate=6e-4, num_envs=128, batch_size=512, grad_updates_per_step=64, max_devices_per_host=1, max_replay_size=1048576, min_replay_size=8192, seed=1),\n",
        "  'walker2d': functools.partial(sac.train, num_timesteps=7_864_320, num_evals=20, reward_scaling=5, episode_length=1000, normalize_observations=True, action_repeat=1, discounting=0.997, learning_rate=6e-4, num_envs=128, batch_size=128, grad_updates_per_step=32, max_devices_per_host=1, max_replay_size=1048576, min_replay_size=8192, seed=1),\n",
        "  'halfcheetah': functools.partial(ppo.train, num_timesteps=50_000_000, num_evals=20, reward_scaling=1, episode_length=1000, normalize_observations=True, action_repeat=1, unroll_length=20, num_minibatches=32, num_updates_per_batch=8, discounting=0.95, learning_rate=3e-4, entropy_cost=0.001, num_envs=2048, batch_size=512, seed=3),\n",
        "  'pusher': functools.partial(ppo.train, num_timesteps=50_000_000, num_evals=20, reward_scaling=5, episode_length=1000, normalize_observations=True, action_repeat=1, unroll_length=30, num_minibatches=16, num_updates_per_batch=8, discounting=0.95, learning_rate=3e-4,entropy_cost=1e-2, num_envs=2048, batch_size=512, seed=3),\n",
        "  'finger': functools.partial(ppo.train, num_timesteps=50_000_000, num_evals=20, reward_scaling=5, episode_length=1000, normalize_observations=True, action_repeat=1, unroll_length=30, num_minibatches=16, num_updates_per_batch=8, discounting=0.95, learning_rate=3e-4,entropy_cost=1e-2, num_envs=2048, batch_size=512, seed=3)\n",
        "}[env_name]\n",
        "\n",
        "epochs = 200\n",
        "seed = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexanderwebb03\u001b[0m (\u001b[33malexanderwebb03-university-of-edinburgh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/alexaldermanwebb/brax/brax/notebooks/wandb/run-20250127_162108-4f7tj0e2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/alexanderwebb03-university-of-edinburgh/Brax/runs/4f7tj0e2' target=\"_blank\">shac_finger_sweep_32</a></strong> to <a href='https://wandb.ai/alexanderwebb03-university-of-edinburgh/Brax' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/alexanderwebb03-university-of-edinburgh/Brax' target=\"_blank\">https://wandb.ai/alexanderwebb03-university-of-edinburgh/Brax</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/alexanderwebb03-university-of-edinburgh/Brax/runs/4f7tj0e2' target=\"_blank\">https://wandb.ai/alexanderwebb03-university-of-edinburgh/Brax/runs/4f7tj0e2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "ZeroDivisionError",
          "evalue": "division by zero",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[38;5;66;03m# log_scalar = lambda key, value: writer.add_scalar(f\"{key}\", value, num_steps)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m   \u001b[38;5;66;03m# for reward in [\"reward\", \"forward_reward\", \"reward_contact\", \"reward_survive\", \"reward_forward\", \"reward_ctrl\", \"x_velocity\", \"y_velocity\"]:\u001b[39;00m\n\u001b[1;32m     15\u001b[0m   \u001b[38;5;66;03m#   log_scalar(f\"eval/episode_{reward}\", metrics[f\"eval/episode_{reward}\"].item())\u001b[39;00m\n\u001b[1;32m     16\u001b[0m   \u001b[38;5;66;03m#   log_scalar(f\"eval/episode_{reward}_std\", metrics[f\"eval/episode_{reward}_std\"].item())\u001b[39;00m\n\u001b[1;32m     18\u001b[0m   writer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m---> 20\u001b[0m make_inference_fn, params, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime to jit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtimes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/brax/brax/brax/training/agents/ppo/train.py:515\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(environment, num_timesteps, episode_length, wrap_env, wrap_env_fn, action_repeat, num_envs, max_devices_per_host, num_eval_envs, learning_rate, entropy_cost, discounting, seed, unroll_length, batch_size, num_minibatches, num_updates_per_batch, num_evals, num_resets_per_eval, normalize_observations, reward_scaling, clipping_epsilon, gae_lambda, deterministic_eval, network_factory, progress_fn, normalize_advantage, eval_env, policy_params_fn, randomization_fn, restore_checkpoint_path, max_grad_norm, madrona_backend, augment_pixels)\u001b[0m\n\u001b[1;32m    511\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m training_state, env_state, metrics  \u001b[38;5;66;03m# pytype: disable=bad-return-type  # py311-upgrade\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;66;03m# Initialize model params and training state.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m init_params \u001b[38;5;241m=\u001b[39m ppo_losses\u001b[38;5;241m.\u001b[39mPPONetworkParams(\n\u001b[0;32m--> 515\u001b[0m     policy\u001b[38;5;241m=\u001b[39m\u001b[43mppo_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_policy\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    516\u001b[0m     value\u001b[38;5;241m=\u001b[39mppo_network\u001b[38;5;241m.\u001b[39mvalue_network\u001b[38;5;241m.\u001b[39minit(key_value),\n\u001b[1;32m    517\u001b[0m )\n\u001b[1;32m    519\u001b[0m obs_shape \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: specs\u001b[38;5;241m.\u001b[39mArray(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:], jnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)), env_state\u001b[38;5;241m.\u001b[39mobs\n\u001b[1;32m    521\u001b[0m )\n\u001b[1;32m    522\u001b[0m training_state \u001b[38;5;241m=\u001b[39m TrainingState(  \u001b[38;5;66;03m# pytype: disable=wrong-arg-types  # jax-ndarray\u001b[39;00m\n\u001b[1;32m    523\u001b[0m     optimizer_state\u001b[38;5;241m=\u001b[39moptimizer\u001b[38;5;241m.\u001b[39minit(init_params),  \u001b[38;5;66;03m# pytype: disable=wrong-arg-types  # numpy-scalars\u001b[39;00m\n\u001b[1;32m    524\u001b[0m     params\u001b[38;5;241m=\u001b[39minit_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    528\u001b[0m     env_steps\u001b[38;5;241m=\u001b[39mjnp\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mjnp\u001b[38;5;241m.\u001b[39mint64),\n\u001b[1;32m    529\u001b[0m )\n",
            "File \u001b[0;32m~/brax/brax/brax/training/networks.py:209\u001b[0m, in \u001b[0;36mmake_policy_network.<locals>.<lambda>\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    206\u001b[0m obs_size \u001b[38;5;241m=\u001b[39m _get_obs_state_size(obs_size, obs_key)\n\u001b[1;32m    207\u001b[0m dummy_obs \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, obs_size))\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FeedForwardNetwork(\n\u001b[0;32m--> 209\u001b[0m     init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m key: \u001b[43mpolicy_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_obs\u001b[49m\u001b[43m)\u001b[49m, apply\u001b[38;5;241m=\u001b[39mapply\n\u001b[1;32m    210\u001b[0m )\n",
            "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
            "File \u001b[0;32m~/brax/brax/brax/training/networks.py:54\u001b[0m, in \u001b[0;36mMLP.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     52\u001b[0m hidden \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, hidden_size \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_sizes):\n\u001b[0;32m---> 54\u001b[0m   hidden \u001b[38;5;241m=\u001b[39m \u001b[43mlinen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m      \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhidden_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkernel_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_sizes) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivate_final:\n\u001b[1;32m     61\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(hidden)\n",
            "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/flax/linen/linear.py:251\u001b[0m, in \u001b[0;36mDense.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;129m@compact\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Array) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Applies a linear transformation to the inputs along the last dimension.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m    The transformed input.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m   kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkernel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[1;32m    258\u001b[0m     bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam(\n\u001b[1;32m    259\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_init, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures,), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_dtype\n\u001b[1;32m    260\u001b[0m     )\n",
            "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
            "File \u001b[0;32m~/anaconda3/envs/brax/lib/python3.10/site-packages/jax/_src/nn/initializers.py:321\u001b[0m, in \u001b[0;36mvariance_scaling.<locals>.init\u001b[0;34m(key, shape, dtype)\u001b[0m\n\u001b[1;32m    319\u001b[0m shape \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mcanonicalize_shape(shape)\n\u001b[1;32m    320\u001b[0m dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mcanonicalize_dtype(dtype)\n\u001b[0;32m--> 321\u001b[0m fan_in, fan_out \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_fans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_axis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfan_in\u001b[39m\u001b[38;5;124m\"\u001b[39m: denominator \u001b[38;5;241m=\u001b[39m fan_in\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfan_out\u001b[39m\u001b[38;5;124m\"\u001b[39m: denominator \u001b[38;5;241m=\u001b[39m fan_out\n",
            "File \u001b[0;32m~/anaconda3/envs/brax/lib/python3.10/site-packages/jax/_src/nn/initializers.py:227\u001b[0m, in \u001b[0;36m_compute_fans\u001b[0;34m(shape, in_axis, out_axis, batch_axis)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m   batch_size \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mprod([shape[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m batch_axis])\n\u001b[0;32m--> 227\u001b[0m receptive_field_size \u001b[38;5;241m=\u001b[39m \u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43min_size\u001b[49m \u001b[38;5;241m/\u001b[39m out_size \u001b[38;5;241m/\u001b[39m batch_size\n\u001b[1;32m    228\u001b[0m fan_in \u001b[38;5;241m=\u001b[39m in_size \u001b[38;5;241m*\u001b[39m receptive_field_size\n\u001b[1;32m    229\u001b[0m fan_out \u001b[38;5;241m=\u001b[39m out_size \u001b[38;5;241m*\u001b[39m receptive_field_size\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ],
      "source": [
        "from importlib import reload\n",
        "reload(brax)\n",
        "\n",
        "times = [datetime.now()]\n",
        "create_wandb_run(\"shac\", env_name, seed, \"test run\")\n",
        "log_dir = os.path.join(\"log\")\n",
        "writer = SummaryWriter(log_dir)\n",
        "\n",
        "def progress(num_steps, metrics):\n",
        "  times.append(datetime.now())\n",
        "  print(num_steps, metrics)\n",
        "\n",
        "  # log_scalar = lambda key, value: writer.add_scalar(f\"{key}\", value, num_steps)\n",
        "  # for reward in [\"reward\", \"forward_reward\", \"reward_contact\", \"reward_survive\", \"reward_forward\", \"reward_ctrl\", \"x_velocity\", \"y_velocity\"]:\n",
        "  #   log_scalar(f\"eval/episode_{reward}\", metrics[f\"eval/episode_{reward}\"].item())\n",
        "  #   log_scalar(f\"eval/episode_{reward}_std\", metrics[f\"eval/episode_{reward}_std\"].item())\n",
        "\n",
        "  writer.flush()\n",
        "\n",
        "make_inference_fn, params, _ = train_fn(environment=env, progress_fn=progress)\n",
        "\n",
        "wandb.finish()\n",
        "\n",
        "print(f'time to jit: {times[1] - times[0]}')\n",
        "print(f'time to train: {times[-1] - times[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjlh7puy2ZM1"
      },
      "source": [
        "The trainers return an inference function, parameters, and the final set of metrics gathered during evaluation.\n",
        "\n",
        "# Saving and Loading Policies\n",
        "\n",
        "Brax can save and load trained policies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gOWeDqlP35sI"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave_params(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/tmp/params\u001b[39m\u001b[38;5;124m'\u001b[39m, params)\n\u001b[1;32m      2\u001b[0m params \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mload_params(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/tmp/params\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m inference_fn \u001b[38;5;241m=\u001b[39m make_inference_fn(params)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "model.save_params('/tmp/params', params)\n",
        "params = model.load_params('/tmp/params')\n",
        "inference_fn = make_inference_fn(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YlZvIG320sK"
      },
      "source": [
        "The trainers return an inference function, parameters, and the final set of metrics gathered during evaluation.\n",
        "\n",
        "# Saving and Loading Policies\n",
        "\n",
        "Brax can save and load trained policies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "height": 480
        },
        "executionInfo": {
          "elapsed": 33520,
          "status": "ok",
          "timestamp": 1679346718844,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "kF5fS-yo35sI",
        "outputId": "94d1a7d5-8d6e-456c-8cfd-94a689b8808f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'envs' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#@title Visualizing a trajectory of the learned inference function\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# create an env with auto-reset\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43menvs\u001b[49m\u001b[38;5;241m.\u001b[39mcreate(env_name\u001b[38;5;241m=\u001b[39menv_name, backend\u001b[38;5;241m=\u001b[39mbackend)\n\u001b[1;32m      6\u001b[0m jit_env_reset \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mjit(env\u001b[38;5;241m.\u001b[39mreset)\n\u001b[1;32m      7\u001b[0m jit_env_step \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mjit(env\u001b[38;5;241m.\u001b[39mstep)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'envs' is not defined"
          ]
        }
      ],
      "source": [
        "#@title Visualizing a trajectory of the learned inference function\n",
        "\n",
        "# create an env with auto-reset\n",
        "env = envs.create(env_name=env_name, backend=backend)\n",
        "\n",
        "jit_env_reset = jax.jit(env.reset)\n",
        "jit_env_step = jax.jit(env.step)\n",
        "jit_inference_fn = jax.jit(inference_fn)\n",
        "\n",
        "rollout = []\n",
        "rng = jax.random.PRNGKey(seed=1)\n",
        "state = jit_env_reset(rng=rng)\n",
        "for _ in range(1000):\n",
        "  rollout.append(state.pipeline_state)\n",
        "  act_rng, rng = jax.random.split(rng)\n",
        "  act, _ = jit_inference_fn(state.obs, act_rng)\n",
        "  state = jit_env_step(state, act)\n",
        "\n",
        "HTML(html.render(env.sys.tree_replace({'opt.timestep': env.dt}), rollout))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBtrAqns35sI"
      },
      "source": [
        "ðŸ™Œ See you soon!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "brax",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
