name: finger
terminal_reward_name: finger

config:
  # schedule parameters
  num_timesteps: 2_000_000

  # environment wrapper
  episode_length: 1000
  action_repeat: 1

  # network parameters
  actor_grad_norm: 1.0
  critic_grad_norm: 1.0
  policy_hidden_layer_sizes: [64, 64]
  value_hidden_layer_sizes: [64, 64]
  tau: 0.2
  betas: [0.7, 0.95]

  # SHAC params
  discounting: 0.97
  normalize_observations: True
  reward_scaling: 10

  # eval
  num_evals: 20
  num_eval_envs: 128
  deterministic_eval: True

ppo:
  learning_rate: 3e-4

diffrl_shac:
  unroll_length: 5
  batch_size: 1024
  num_minibatches: 32
  num_updates_per_batch: 16
  num_envs: 2048 

  actor_lr: 1e-3
  critic_lr: 1e-2
